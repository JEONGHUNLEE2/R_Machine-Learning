#6주차

#R에서는 vector 가 다 같아야한다. 
#num은 실수, int정수 
#강제변환 
#R에서는 인코딩 비츄?

#파이썬에서는 원핫인코딩 해야하지만 
#R에서는 범주형으로 바꿔주는것으로 충분히 해결된다.


#---------------------수업
#6주차 랜덤포레스트
#해석이 어렵지만 변수의 중요도를 알수 있따. 

#앙상블

library(tidyverse)
rm(list = ls())
list.files()
load(file = 'Bank_DataSet.RDA')


#install.packages("randomForest")
library(randomForest)

set.seed(seed = 1234)
fit1<-randomForest(formula = PersonalLoan ~.,
                   data = trainSet,
                   ntree = 1000,
                   mtry = 3,
                   importance = TRUE,
                   do.trace = 50,
                   keep.forest = TRUE)


print(fit1)
print(fit1$err.rate)
print(fit1$err.rate[,1])


#
#정확도 평균 감소량, 클수록 중요한 변수
#변수가 쓰인 모형 - 쓰이지 않은 모형
importance(fit1,type = 1)
varImpPlot(fit1, type = 1)

real <- testSet$PersonalLoan
pred1 <- predict(fit1, newdata = testSet, )

#--- 강사님 
treesize(x = fit1, terminal = TRUE) %>% hist()
real <- testSet$PersonalLoan

pred1 <- predict(object = fit1, newdata = testSet, type = 'response')
table(pred1, real)
prob1 <- predict(object = fit1, newdata = testSet, type = 'vote')[, 2]
head(x = prob1)
library(caret)
confusionMatrix(data = pred1, reference = real, positive = '1')
library(MLmetrics)
F1_Score(y_true = real, y_pred = pred1, positive = '1')
library(pROC)
roc(response = real, predictor = prob1) %>%
  plot(main = 'ROC Curve', col = 'red', lty = 1)
auc(response = real, predictor = prob1)
list.files()
fitDT <- readRDS(file = 'DecisionTree.RDS')
pred0 <- predict(object = fitDT, newdata = testSet, type = 'class')
confusionMatrix(data = pred1, reference = real, positive = '1')
confusionMatrix(data = pred0, reference = real, positive = '1')
F1_Score(y_true = real, y_pred = pred1, positive = '1')
F1_Score(y_true = real, y_pred = pred0, positive = '1')
prob0 <- predict(object = fitDT, newdata = testSet, type = 'prob')[, 2]
roc(response = real, predictor = prob0) %>%
  plot(col = 'blue', lty = 2, add = TRUE)
auc(response = real, predictor = prob0)


#----
grid <- expand.grid(ntree = c(300,500,700,1000),
                    mtry = 3:7,
                    error = NA)

n <- nrow(grid)
for(i in 1:n){
  ntree <- grid$ntree[i]
  mtry <- grid$mtry[i]
  disp <- str_glue('현재 {i}번째 행 실행 중! [ntree : {ntree}, mtry : {mtry}]')
  cat(disp, '\n\n')
  
  set.seed(seed=1234)
  fit <- randomForest(formula = PersonalLoan ~.,
                      data = trainSet,
                      ntree = ntree,
                      mtry = mtry)
  
  grid$error[i] <- tail(x = fit$err.rate[,1],n = 1L)
  
}

plot(grid$error, type = 'b', pch = 19, col = 'red',
     main = 'grid search result')

abline(h = min(grid$error), col = 'red', lty = 2)

loc <- which.min(x = grid$error)
print(loc)

bestPara <- grid[loc,]
print(bestPara)

set.seed(seed = 1234)
best<- randomForest(formula = PersonalLoan ~.,
                    data = trainSet,
                    ntree = bestPara$ntree,
                    mtry = bestPara$mtry,
                    importance = TRUE)

print(best)
print(fit1)

plot(best)
importance(best, type = 1)
varImpPlot(best, type = 1)
#해석방법 : 분류모형에 집중
#목표변수가 명목형 
#income, 과 edu 중요하다고 나왔습니다.
#박스플랏 그려보니까 이러이렇게 나오고
#다른것도 이러쿵저러쿵
#교육수준이 2#@$한 사람부터 타켓팅합시다!
boxplot(formula = Income ~ PersonalLoan, data = trainSet)


saveRDS(best, file = 'RandomForest.RDS')

#시험셋으로 추정라벨 뽑은거 
print(pred2)
#다수결로 라벨링한거.

#상관분석 할 때 
